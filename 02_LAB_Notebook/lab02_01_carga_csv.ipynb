{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2f79591-d1a0-44d5-b219-5a067c9f91ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Databricks-BR/lab_sql/main/images/header_notebook.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7cc1fdd-f01b-4c1c-835a-df403bf26cd1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Controle de Alteração de Versões\n",
    "\n",
    "| versão | data | autor | e-mail | alterações |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 1.0 | 20-JUN-2023 | Luis Assunção | luis.assuncao@databricks.com | Primeira versão (criação de massa de dados) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62dd77a1-0e46-4afe-95ff-14bfa7dac629",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Descrição\n",
    "\n",
    "| projeto | aplicação | módulo | tabela | objetivo |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| ACADEMY | Laboratório 2 | ETL Bronze | Diversas CSV | Ingestão de arquivos publicos CSV - bases de teste para o Treinamento de SQL |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5af31e35-6373-417e-99d3-bfb57c499fd2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Referências\n",
    "* [Leitura de Arquivos CSV](https://learn.microsoft.com/pt-br/azure/databricks/external-data/csv)\n",
    "* [Notebook Exemplo - CSV](https://docs.databricks.com/_extras/notebooks/source/read-csv-files.html)\n",
    "* [Salvando uma Tabela DELTA](https://docs.databricks.com/delta/tutorial.html#create-a-table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05476df0-f786-4202-8ebe-2c2e500320ea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Parâmetros Iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a467ff1-53c5-45b2-9767-abdc27d98f09",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "url = f\"https://raw.githubusercontent.com//Databricks-BR/lab_sql/main/dados/\"\n",
    "catalog_name = f\"academy\"\n",
    "prefix_table = f\"bronze\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b80f9d7c-8154-4ac8-a298-412b4c487624",
     "showTitle": true,
     "title": "ALTERE ESSE PARAMETRO"
    }
   },
   "outputs": [],
   "source": [
    "#schema_name  = f\"<<<<<-----COLOQUE SEU USER NAME AQUI --------->>>>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2be65657-c09a-405d-9786-4542f6858c39",
     "showTitle": true,
     "title": "Gravando a tabela DELTA - dolar"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"dolar\"\n",
    "\n",
    "table_name   = f\"{catalog_name}.{schema_name}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # grava o DataFrame na Tabela Delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23edce93-c276-4bc2-ad08-d9379e9ba226",
     "showTitle": true,
     "title": "Gravando a tabela DELTA - CNAE"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"cnae\"\n",
    "\n",
    "table_name   = f\"{catalog_name}.{schema_name}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # grava o DataFrame na Tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5eb8337-343e-49fe-a29f-7716eca07c2d",
     "showTitle": true,
     "title": "Gravando a tabela DELTA - empresas"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"empresas\"\n",
    "\n",
    "table_name   = f\"{catalog_name}.{schema_name}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # grava o DataFrame na Tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32069678-7caf-4318-8a95-af8f6438263e",
     "showTitle": true,
     "title": "Gravando a tabela DELTA - estabelecimentos"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"estabelecimentos\"\n",
    "\n",
    "table_name   = f\"{catalog_name}.{schema_name}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # grava o DataFrame na Tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d016c9fb-f538-4534-9897-7b20478a541f",
     "showTitle": true,
     "title": "Gravando a tabela DELTA - municipios"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"municipios\"\n",
    "\n",
    "table_name   = f\"{catalog_name}.{schema_name}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # grava o DataFrame na Tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c90d01b9-0277-4c05-a443-9153262331cb",
     "showTitle": true,
     "title": "Gravando a tabela DELTA - naturezas"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"naturezas\"\n",
    "\n",
    "table_name   = f\"{catalog_name}.{schema_name}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # grava o DataFrame na Tabela Delta"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 597306790085131,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "lab02_01_carga_csv",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
